{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('/Users/paramanandbhat/Downloads/test_fkwGUNG.csv')\n",
    "base_path = '/Users/paramanandbhat/Downloads/train_nLPp5K8/images'\n",
    "\n",
    "# Update the image paths in the DataFrame\n",
    "train_df['image_path'] = base_path + '/' + train_df['image_names'].astype(str)\n",
    "test_df['image_path'] = base_path + '/' + test_df['image_names'].astype(str)\n",
    "\n",
    "# Verify that an image file exists (optional)\n",
    "print(os.path.exists(train_df['image_path'].iloc[0]))\n",
    "\n",
    "# Convert the 'class' column to string type\n",
    "train_df['class'] = train_df['class'].astype(str)\n",
    "\n",
    "# Data augmentation\n",
    "# Example using ImageDataGenerator with additional augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # New augmentation\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Prepare the data generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "# Simplified Model Architecture\n",
    "# Adding more convolutional layers and increasing depth\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(256, (3, 3), activation='relu'),  # New layer\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),  # Increased units\n",
    "    Dropout(0.5),  # Keep high dropout to combat overfitting\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "# Compile the model with a potentially lower initial learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Adjusted learning rate\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Extended patience for EarlyStopping\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),  # Increased patience\n",
    "    ModelCheckpoint('best_model_simplified.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "]\n",
    "\n",
    "# Using ReduceLROnPlateau for dynamic learning rate adjustments\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "\n",
    "# Increased training epochs with EarlyStopping in place\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50,  # Allowing for more epochs with early stopping\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "# Plot training and validation accuracy and loss\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Preprocess and predict on test images\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "preprocessed_images = np.vstack([preprocess_image(path) for path in test_df['image_path']])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(preprocessed_images)\n",
    "predicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "# Prepare submission\n",
    "test_df['class'] = predicted_classes\n",
    "submission_df = test_df[['image_names', 'class']]\n",
    "submission_df.to_csv('/Users/paramanandbhat/Downloads/train_nLPp5K8/submissionfinal4.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

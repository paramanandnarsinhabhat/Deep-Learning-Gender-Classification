{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the files\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('/Users/paramanandbhat/Downloads/train_nLPp5K8.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('/Users/paramanandbhat/Downloads/test_fkwGUNG.csv')\n",
    "base_path = '/Users/paramanandbhat/Downloads/train_nLPp5K8/images'\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "!pip install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a train-validation split\n",
    "train_df['image_path'] = train_df['image_names'].apply(lambda x: f'{base_path}/{x}.jpg')\n",
    "train, val = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Convert the 'class' column to string type\n",
    "train_df['class'] = train_df['class'].astype(str)\n",
    "\n",
    "# Now, create the train_generator with the modified DataFrame\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',  # Ensure this column contains the full path to the images\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Update the image paths in the DataFrame\n",
    "train_df['image_path'] = '/Users/paramanandbhat/Downloads/train_nLPp5K8/images/' + train_df['image_names'].astype(str)\n",
    "# Check the first few image paths\n",
    "print(train_df['image_path'].head())\n",
    "\n",
    "# Verify the existence of the first image file\n",
    "import os\n",
    "first_image_path = train_df['image_path'].iloc[0]\n",
    "print(f\"Does the first image file exist? {os.path.exists(first_image_path)}\")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Create a train and val split\n",
    "# Create a train-validation split\n",
    "train, val = train_test_split(train_df, test_size=0.2)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Assuming train_datagen has already been defined with the desired configurations\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Example, adjust according to your needs\n",
    "\n",
    "# Create the train_generator using the flow_from_dataframe method\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=None,\n",
    "    x_col='image_path',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val,\n",
    "    directory=None,\n",
    "    x_col='image_path',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "#building and training a simple convolutional neural network (CNN) model for your gender classification task using TensorFlow and Keras\n",
    "#Step 1: Import Necessary Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#Step 2: Define Your Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout layer to reduce overfitting\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "# Use the legacy Adam optimizer for potentially better performance on M1/M2 Macs\n",
    "model.compile(optimizer=legacy.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the test.csv file\n",
    "test_df = pd.read_csv('/Users/paramanandbhat/Downloads/test_fkwGUNG.csv')\n",
    "\n",
    "#  test images are in the same folder structure as  training images\n",
    "test_images_directory = '/Users/paramanandbhat/Downloads/train_nLPp5K8/images/'\n",
    "\n",
    "# Construct the full image paths\n",
    "test_df['image_path'] = test_images_directory + test_df['image_names'].astype(str)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "# Preprocess all test images\n",
    "preprocessed_images = np.vstack([preprocess_image(path) for path in test_df['image_path']])\n",
    "\n",
    "predictions = model.predict(preprocessed_images)\n",
    "# Assuming your model outputs probabilities for being in one class, e.g., female\n",
    "# Convert probabilities to binary class labels based on a threshold\n",
    "predicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "# Add the predicted classes to test_df\n",
    "test_df['class'] = predicted_classes\n",
    "\n",
    "# If required, adjust column names and order to match the submission format\n",
    "submission_df = test_df[['image_names', 'class']]\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "submission_df.to_csv('/Users/paramanandbhat/Downloads/train_nLPp5K8/submissionfinal.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
